---
id: '008-nodejs-rorw-delay-debug'
title: '[Node.js] RO/RW 복제 지연 이슈 분석기'
date: '2025-06-02'
description: '정상 처리된 응답인데 데이터가 오지 않는 상황에 대해 분석해보고 재현 및 해결해보기'
---

# [Node.js] RO/RW 복제 지연 이슈 분석기
<MdxDivider />

## 개요

서비스 운영 중, 몇몇 기기나 사용자에게만 발생하는 특이한 문제가 있었습니다. INSERT 이후 SELECT로 결과를 반환하는 API가 정상적으로 호출되었고 응답도 완료되었음에도 불구하고, 클라이언트에서는 데이터를 받지 못하고 동일한 SELECT 요청을 한 번 더 보내야만 결과가 제대로 나타나는 현상이었습니다.

Query 조건문 오류, async/await 처리 문제, DB에 저장된 데이터 자체의 이상 등 발생할 수 있는 모든 가능성을 의심해봤지만, 원인은 전혀 다른 곳에 있었습니다. 분석과 재현 과정을 거치면서 문제의 원인은 `ReadOnly(이하 RO)와 ReadWrite(이하 RW) DB` 간의 동기화 지연에 있었다는 것을 확인할 수 있었습니다.

이번 포스팅에서는 어떤 과정을 거쳐서 원인을 분석하고 재현 및 테스트하여 배포까지 완료하였는지를 공유해보려 합니다.

---

## RO, RW DB 정의 및 원리

#### RO, RW 의 정의

문제 해결 과정을 설명하기에 앞서 간단하게 `RO, RW DB` 의 정의를 짚고 넘어가려 합니다.<br />
`RO DB` 란 데이터베이스에서 읽기 작업(SELECT)만을 처리하는 데이터베이스로, 쓰기 작업은 불가능한 데이터베이스입니다.
`RW DB` 란 데이터베이스에서 쓰기 작업(INSERT, UPDATE, DELETE)을 수행하는 데이터베이스입니다.
<br />

#### RO, RW 의 원리

`RW DB`와 `RO DB` 는 데이터베이스 복제를 통해 구성됩니다. Master-Slave replication 을 통해 `RW(Master) DB`에서 발생한 모든 변경사항을 `RO(Slave) DB`로 복제하는 방식이며 Slave 서버는 여럿을 두어 읽기 부하를 분산할 수 있습니다.<br />
복제 방식에는 비동기/동기 복제가 있습니다. 비동기 복제는 `RW DB`  에서 발생한 변경사항이 즉시 `RO DB` 에 반영되지 않습니다. 비록 데이터 일관성 문제가 발생할 수 있지만, 성능은 더 좋습니다. 동기 복제는 `RW DB`와 `RO DB`가 동기화된 상태에서 변경사항을 처리합니다. 다만, 데이터 일관성은 보장되지만 속도가 느릴 수 있습니다.<br />
정리하자면 `RW DB`는 쓰기 작업을 처리하고, `RO DB`는 읽기 작업을 처리하여 부하를 분산시키며 보통 성능 최적화, 데이터 보호 등의 장점을 위해 많이 사용됩니다.

---

## 문제에 대한 분석 과정

#### 문제의 코드

이제 본격적으로 문제의 핵심으로 들어가 보겠습니다. 실제 이슈가 발생했던 코드는 다음과 같은 형태였습니다.

```flow
async function main() {
    const pgReadWriteConfig = {
        host: 'localhost',
        port: 5433,
        user: 'postgres',
        password: '',
        database: 'postgres',
    };

    const pgReadOnlyConfig = {
        host: 'localhost',
        port: 5434,
        user: 'postgres',
        password: '',
        database: 'postgres',
    };

    const pgReadWritePool = new Pool(pgReadWriteConfig);
    const pgReadOnlyPool = new Pool(pgReadOnlyConfig);

		await pgReadWritePool.transaction(async (conn) => {
				await conn.query(`
		        INSERT INTO test(id, data) VALUES ($1, $2)
		    `, ['id1', 'data1']);

				await conn.query(`
		        INSERT INTO test(id, data) VALUES ($1, $2)
		    `, ['id2', 'data2']);
		})

	  const result = await pgReadOnlyPool.query(`
        SELECT count(*) FROM test
    `);
    
    return result.rows[0].count;
}

main();
```

문제의 코드를 처음 봤을 때는 단순한 INSERT 후 SELECT 로직이었기 때문에, 겉보기엔 특별한 이상이 없어 보였습니다. 하지만 결과가 제대로 반환되지 않는 현상이 분명 발생하였기 때문에 아래와 같은 분석과정을 통해 원인을 찾고 해결하였습니다.
<br />

#### 문제 분석 과정

**1. DB 데이터 문제**

가장 먼저 잘못된 데이터가 이미 DB에 존재하거나, 특정 상황에서 데이터가 INSERT되지 않는 케이스가 있는지 확인했습니다. 테스트 환경과 운영 환경에서 테스트를 진행하며 데이터를 확인했지만, INSERT 자체는 정상적으로 수행되고 있었습니다.

<br />
**2. Query 조건문 문제**

다음은 SQL 쿼리의 조건문을 확인했습니다. WHERE 절이나 필터 조건이 잘못되어 결과가 누락될 가능성이 있었기 때문입니다. 하지만 쿼리는 단순한 형태였고 문제가 없었습니다.

<br />
**3. async/await 처리 문제**

사실 해당 현상의 가장 유력한 후보였습니다. 비동기 흐름에서 await을 빼먹어 쿼리 순서가 뒤섞이거나, 아직 커밋되지 않은 데이터를 조회하는 상황은 가끔 발생하기 때문입니다. 하지만 이 부분도 문제가 아니였습니다.

<br />
**4. Slonik 트랜잭션 메서드 의심**

일반적인 가능성들은 모두 점검을 마쳤기에, 이제 보다 깊은 수준에서 원인을 찾아보기로 했습니다.
사내에서는 PostgreSQL과의 통신에 Slonik 라이브러리를 사용하고 있었기 때문에, 혹시 트랜잭션 처리 방식에 문제가 있는 것은 아닌지 의심해보았습니다. 이를 확인하기 위해 Slonik 의 transaction 메서드 내부 구현을 살펴본 결과, 해당 메서드는 node-postgres 의 트랜잭션 기능을 기반으로 확장된 구조였고, 구조상 특별한 이상은 보이지 않았습니다. 또한, 간단한 테스트를 통해 동작도 검증해봤지만 문제는 재현되지 않았습니다.

<br />
**5. RO/RW DB 복제 지연 문제**

위 과정까지 진행한 시점에서, 백엔드 파트에서 확인할 수 있는 모든 가능성은 충분히 점검했다고 판단했습니다. 이에 따라 혹시 네트워크나 인프라 레벨에서 문제가 있는 건 아닌지 확인하고자 인프라팀과 함께 점검을 시작했고, 그 과정에서 원인을 찾아낼 수 있었습니다.
사내 AWS 환경은 마스터-리드 구조로 설정된 비동기 복제 환경이었고, 실제로 확인해본 결과 `약 0.2초의 복제 지연`이 발생하고 있었습니다. 이 짧은 지연이 특정 상황에서 데이터 미반영처럼 보이는 문제로 이어졌던 것입니다.

---

## RO, RW 비동기 복제 지연 재현

테스트 서버에서 이 문제를 정밀하게 재현하는 것은 현실적으로 까다로운 부분이 있었고, 이미 원인에 대해 어느 정도 확신이 선 상황이었기 때문에, 아래와 같은 과정을 통해 로컬 환경에서 간단하게 문제를 재현한 뒤 해결을 확인하고 hotfix 로 빠르게 배포하여 대응하는 방식을 선택했습니다.

<br />
#### 디렉토리 구조

원하는 위치에 PostgreSQL readwrite, readonly 데이터베이스 설정 값을 저장할 디렉토리를 생성합니다.
```bash
~/pg_custom_config
├── read_write
└── read_only
```

<br />
#### RW DB 생성

PostgreSQL 명령어 `initdb` 를 사용해 RW 데이터베이스 클러스터를 생성합니다.
```bash
initdb -D ~/pg_custom_config/read_write
```

<br />
각 데이터베이스를 로컬에서 다른 포트로 띄우고 복제 지연을 구현하기 위해 `postgresql.conf` 파일 중 다음 값을 수정합니다.<br />
(주석처리 되어있는 부분은 주석 해제하고 수정합니다.)
```bash
# 파일경로) ~/pg_custom_config/read_write/postgresql.conf
listen_addresses = 'localhost'   # 로컬만 허용
port = 5433                      # RW DB는 로컬 5433 포트를 사용
wal_level = replica              # WAL 로그를 복제 모드로 설정
max_wal_senders = 2              # 최대 2개(RW/RO) 의 리플리카가 동작 가능하도록 설정
synchronous_commit = off         # 비동기 복제 기능 끄기
wal_writer_delay = 20ms          # WAL을 디스크에 기록하는 주기 (AWS에서 측정된 복제 지연 시간인 0.2초로 설정)

listen_addresses = 'localhost'
port = 5434                      # 리플리카는 5434 포트 사용
hot_standby = on                 # 리플리카에서 읽기 쿼리 허용
```

<br />
복제본(RO DB)이 리더에 접근할 수 있도록 인증을 허용하기 위해 `pg_hba.conf` 파일을 확인 및 수정합니다.
```bash
# 파일경로) ~/pg_custom_config/read_write/pg_hba.conf
host replication all 127.0.0.1/32 trust # 값이 설정되었는지 확인
```

<br />
RW DB를 실행시킵니다.
```bash
pg_ctl -D ~/pg_custom_config/read_write -l ~/pg_custom_config/read_write/postgresql.log start
```

<br />
RW DB가 정상적으로 실행되었는지 테스트해봅니다.
```bash
psql -p 5433 -d postgres -c "SELECT 1"
```

<br />
#### RO DB 생성
구현 완료된 RW 데이터베이스를 바탕으로 PostgreSQL 명령어 `pg_basebackup` 를 사용하여 RO 데이터베이스 클러스터를 복제 및 생성합니다.

```bash
# -h: 호스트
# -p: RW 데이터베이스 포트 번호
# -D: 백업을 저장할 대상 디렉토리를 지정
# -R: 리플리카 설정 파일(recovery.conf)을 자동으로 생성
# -P: 백업 진행 상황을 표시
# -X: WAL 로그를 스트리밍 방식으로 백업하도록 지정

pg_basebackup -h localhost -p 5433 -D ~/pg_custom_config/read_only -R -P -X stream
```

<br />
RO DB를 로컬에서 다른 포트로 띄우고 복제 모드로 구현하기 위해 `postgresql.conf` 파일 중 다음 값을 수정합니다.<br />
```bash
# 파일경로) ~/pg_custom_config/read_only/postgresql.conf
listen_addresses = 'localhost'   # 로컬만 허용
port = 5434                      # RO DB는 로컬 5434 포트를 사용
wal_level = replica              # WAL 로그를 복제 모드로 설정
max_wal_senders = 2              # 제거
synchronous_commit = off         # 제거
wal_writer_delay = 1000ms        # 제거
```

<br />
데이터 복제를 위해 디렉토리 권한 부여시킵니다.
```bash
chmod 0700 ./pg_custom_config/read_only
```

<br />
RO DB를 실행시킵니다.
```bash
pg_ctl -D ~/pg_custom_config/read_only -l ~/pg_custom_config/read_only/postgresql.log start
```

<br />
RO DB가 정상적으로 실행되었는지 테스트해봅니다.
```bash
psql -p 5434 -d postgres -c "SELECT 1"
```

<br />
#### 테스트 코드를 통한 검증
아래와 같은 테스트 코드를 통해 비동기 복제 지연 시간 0.2초가 정상적으로 구현되었는지 확인해봅니다.
```tsx
import {Pool} from 'pg';

async function getTestCount(pool: Pool, type: 'rw' | 'ro', message: string): Promise<void> {
    const result = await pool.query(`
        SELECT count(*) FROM test
    `);

    console.log(`${message} ${type.toUpperCase()} DB data: ${result.rows[0].count}`);
}

async function setTestCount(pool: Pool): Promise<void> {
    await pool.query(`
        INSERT INTO test (id, data) SELECT generate_series(1, 100), 'data'
    `);
    console.log('========== Insert done  ==========');
}

async function sleep() {
    console.log('========== Sleep start ==========');
    await new Promise((resolve) => setTimeout(resolve, 4 * 10)); // 복제 지연 20ms의 딜레이를 감안하여 2배 값인 40ms로 설정
    console.log('========== Sleep done  ==========');
}

export default async function main() {
    const pgReadWriteConfig = {
        host: 'localhost',
        port: 5433,
        user: 'postgres',
        password: '',
        database: 'postgres',
    };

    const pgReadOnlyConfig = {
        host: 'localhost',
        port: 5434,
        user: 'postgres',
        password: '',
        database: 'postgres',
    };

    const pgReadWritePool = new Pool(pgReadWriteConfig);
    const pgReadOnlyPool = new Pool(pgReadOnlyConfig);

    // SELECT
    await getTestCount(pgReadWritePool, 'rw', 'Before Insert');
    await getTestCount(pgReadOnlyPool, 'ro', 'Before Insert');

    // INSERT
    await setTestCount(pgReadWritePool);

    // SELECT
    await getTestCount(pgReadWritePool, 'rw', 'After Insert');
    await getTestCount(pgReadOnlyPool, 'ro', 'After Insert');

    await sleep();

    // SELECT
    await getTestCount(pgReadWritePool, 'rw', 'After Sleep');
    await getTestCount(pgReadOnlyPool, 'ro', 'After Sleep');
}

```

<br />
출력 결과는 다음과 같았으며, 지연 시간이 정상적으로 구현되었음을 확인할 수 있습니다.
```bash
Before Insert RW DB data: 200
Before Insert RO DB data: 200
========== Insert done  ==========
After Insert RW DB data: 300
After Insert RO DB data: 200
========== Sleep start ==========
========== Sleep done  ==========
After Sleep RW DB data: 300
After Sleep RO DB data: 300
```

---

## 코드 수정 및 배포
비동기 복제 방식을 동기 복제 방식으로 바꾸는 것은 어려웠기 때문에, 코드 로직을 수정하기로 했습니다.<br />
코드는 기존 RO 커넥션을 사용하지 않고 RW 커넥션만을 사용하도록 수정했으며, 트랜잭션 내부에서 SELECT를 수행하도록 수정하여 데이터를 바로 조회할 수 있도록 변경했습니다.
성능에 큰 영향을 주지 않는 수준이었기에 해당 방식을 적용했고, 구현했던 테스트 로직을 그대로 사용하여 정상 동작을 확인한 후 서버에 배포를 진행하여 문제를 해결했습니다.

<br />
아래는 최종적으로 배포된 코드입니다.
```tsx
async function main() {
    const pgReadWriteConfig = {
        host: 'localhost',
        port: 5433,
        user: 'postgres',
        password: '',
        database: 'postgres',
    };

    const pgReadOnlyConfig = {
        host: 'localhost',
        port: 5434,
        user: 'postgres',
        password: '',
        database: 'postgres',
    };

    const pgReadWritePool = new Pool(pgReadWriteConfig);
    const pgReadOnlyPool = new Pool(pgReadOnlyConfig);

    const result = await pgReadWritePool.transaction(async (conn) => {
        await conn.query(`
            INSERT INTO test(id, data) VALUES($1, $2)
        `, ['id1', 'data1']);

        await conn.query(`
            INSERT INTO test(id, data) VALUES ($1, $2)
        `, ['id2', 'data2']);


        return await conn.query (`
            SELECT count(*) FROM test
        `)
    })

    return result.rows[0].count;
}

main();
```
